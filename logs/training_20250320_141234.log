Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|#####     | 1/2 [00:00<00:00,  1.61it/s]Loading checkpoint shards: 100%|##########| 2/2 [00:01<00:00,  1.87it/s]Loading checkpoint shards: 100%|##########| 2/2 [00:01<00:00,  1.82it/s]
/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py:390: UserWarning: The requested device cuda:0 is also being used for training. For higher throughput and to avoid out-of-memory errors, it is recommended to use a dedicated device for vLLM. If this is intentional, you may ignore this warning but should adjust `vllm_gpu_memory_utilization` accordingly.
  warnings.warn(
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.18it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.76it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.64it/s]

Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|2         | 1/35 [00:00<00:16,  2.02it/s]Capturing CUDA graph shapes:   6%|5         | 2/35 [00:00<00:14,  2.32it/s]Capturing CUDA graph shapes:   9%|8         | 3/35 [00:01<00:13,  2.46it/s]Capturing CUDA graph shapes:  11%|#1        | 4/35 [00:01<00:12,  2.50it/s]Capturing CUDA graph shapes:  14%|#4        | 5/35 [00:02<00:11,  2.50it/s]Capturing CUDA graph shapes:  17%|#7        | 6/35 [00:02<00:10,  2.64it/s]Capturing CUDA graph shapes:  20%|##        | 7/35 [00:02<00:10,  2.73it/s]Capturing CUDA graph shapes:  23%|##2       | 8/35 [00:03<00:09,  2.81it/s]Capturing CUDA graph shapes:  26%|##5       | 9/35 [00:03<00:09,  2.86it/s]Capturing CUDA graph shapes:  29%|##8       | 10/35 [00:03<00:08,  2.89it/s]Capturing CUDA graph shapes:  31%|###1      | 11/35 [00:04<00:08,  2.92it/s]Capturing CUDA graph shapes:  34%|###4      | 12/35 [00:04<00:07,  2.94it/s]Capturing CUDA graph shapes:  37%|###7      | 13/35 [00:04<00:07,  2.94it/s]Capturing CUDA graph shapes:  40%|####      | 14/35 [00:05<00:07,  2.94it/s]Capturing CUDA graph shapes:  43%|####2     | 15/35 [00:05<00:06,  2.94it/s]Capturing CUDA graph shapes:  46%|####5     | 16/35 [00:05<00:06,  2.94it/s]Capturing CUDA graph shapes:  49%|####8     | 17/35 [00:06<00:06,  2.95it/s]Capturing CUDA graph shapes:  51%|#####1    | 18/35 [00:06<00:05,  2.94it/s]Capturing CUDA graph shapes:  54%|#####4    | 19/35 [00:06<00:05,  2.94it/s]Capturing CUDA graph shapes:  57%|#####7    | 20/35 [00:07<00:05,  2.93it/s]Capturing CUDA graph shapes:  60%|######    | 21/35 [00:07<00:04,  2.95it/s]Capturing CUDA graph shapes:  63%|######2   | 22/35 [00:07<00:04,  2.91it/s]Capturing CUDA graph shapes:  66%|######5   | 23/35 [00:08<00:04,  2.93it/s]Capturing CUDA graph shapes:  69%|######8   | 24/35 [00:08<00:03,  2.92it/s]Capturing CUDA graph shapes:  71%|#######1  | 25/35 [00:08<00:03,  2.91it/s]Capturing CUDA graph shapes:  74%|#######4  | 26/35 [00:09<00:03,  2.91it/s]Capturing CUDA graph shapes:  77%|#######7  | 27/35 [00:09<00:02,  2.91it/s]Capturing CUDA graph shapes:  80%|########  | 28/35 [00:09<00:02,  2.90it/s]Capturing CUDA graph shapes:  83%|########2 | 29/35 [00:10<00:02,  2.87it/s]Capturing CUDA graph shapes:  86%|########5 | 30/35 [00:10<00:01,  2.90it/s]Capturing CUDA graph shapes:  89%|########8 | 31/35 [00:10<00:01,  2.84it/s]Capturing CUDA graph shapes:  91%|#########1| 32/35 [00:11<00:01,  2.86it/s]Capturing CUDA graph shapes:  94%|#########4| 33/35 [00:11<00:00,  2.90it/s]Capturing CUDA graph shapes:  97%|#########7| 34/35 [00:11<00:00,  2.92it/s]Capturing CUDA graph shapes: 100%|##########| 35/35 [00:12<00:00,  2.88it/s]Capturing CUDA graph shapes: 100%|##########| 35/35 [00:12<00:00,  2.84it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|#####     | 1/2 [00:00<00:00,  1.29it/s]Loading checkpoint shards: 100%|##########| 2/2 [00:01<00:00,  1.59it/s]Loading checkpoint shards: 100%|##########| 2/2 [00:01<00:00,  1.54it/s]
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.16it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.73it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.61it/s]

Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|2         | 1/35 [00:00<00:27,  1.25it/s]Capturing CUDA graph shapes:   6%|5         | 2/35 [00:01<00:25,  1.28it/s]Capturing CUDA graph shapes:   9%|8         | 3/35 [00:02<00:24,  1.30it/s]Capturing CUDA graph shapes:  11%|#1        | 4/35 [00:03<00:23,  1.32it/s]Capturing CUDA graph shapes:  14%|#4        | 5/35 [00:03<00:21,  1.40it/s]Capturing CUDA graph shapes:  17%|#7        | 6/35 [00:04<00:19,  1.47it/s]Capturing CUDA graph shapes:  20%|##        | 7/35 [00:04<00:18,  1.51it/s]Capturing CUDA graph shapes:  23%|##2       | 8/35 [00:05<00:17,  1.54it/s]Capturing CUDA graph shapes:  26%|##5       | 9/35 [00:06<00:16,  1.54it/s]Capturing CUDA graph shapes:  29%|##8       | 10/35 [00:06<00:16,  1.54it/s]Capturing CUDA graph shapes:  31%|###1      | 11/35 [00:07<00:15,  1.56it/s]Capturing CUDA graph shapes:  34%|###4      | 12/35 [00:08<00:14,  1.57it/s]Capturing CUDA graph shapes:  37%|###7      | 13/35 [00:08<00:14,  1.57it/s]Capturing CUDA graph shapes:  40%|####      | 14/35 [00:09<00:13,  1.58it/s]Capturing CUDA graph shapes:  43%|####2     | 15/35 [00:09<00:12,  1.58it/s]Capturing CUDA graph shapes:  46%|####5     | 16/35 [00:10<00:11,  1.59it/s]Capturing CUDA graph shapes:  49%|####8     | 17/35 [00:11<00:11,  1.59it/s]Capturing CUDA graph shapes:  51%|#####1    | 18/35 [00:11<00:10,  1.59it/s]Capturing CUDA graph shapes:  54%|#####4    | 19/35 [00:12<00:10,  1.60it/s]Capturing CUDA graph shapes:  57%|#####7    | 20/35 [00:13<00:09,  1.60it/s]Capturing CUDA graph shapes:  60%|######    | 21/35 [00:13<00:08,  1.60it/s]Capturing CUDA graph shapes:  63%|######2   | 22/35 [00:14<00:08,  1.61it/s]Capturing CUDA graph shapes:  66%|######5   | 23/35 [00:14<00:07,  1.60it/s]Capturing CUDA graph shapes:  69%|######8   | 24/35 [00:15<00:06,  1.61it/s]Capturing CUDA graph shapes:  71%|#######1  | 25/35 [00:16<00:06,  1.61it/s]Capturing CUDA graph shapes:  74%|#######4  | 26/35 [00:16<00:05,  1.61it/s]Capturing CUDA graph shapes:  77%|#######7  | 27/35 [00:17<00:04,  1.61it/s]Capturing CUDA graph shapes:  80%|########  | 28/35 [00:18<00:04,  1.61it/s]Capturing CUDA graph shapes:  83%|########2 | 29/35 [00:18<00:03,  1.60it/s]Capturing CUDA graph shapes:  86%|########5 | 30/35 [00:19<00:03,  1.58it/s]Capturing CUDA graph shapes:  89%|########8 | 31/35 [00:19<00:02,  1.59it/s]Capturing CUDA graph shapes:  91%|#########1| 32/35 [00:20<00:01,  1.59it/s]Capturing CUDA graph shapes:  94%|#########4| 33/35 [00:21<00:01,  1.60it/s]Capturing CUDA graph shapes:  97%|#########7| 34/35 [00:21<00:00,  1.60it/s]Capturing CUDA graph shapes: 100%|##########| 35/35 [00:22<00:00,  1.60it/s]Capturing CUDA graph shapes: 100%|##########| 35/35 [00:22<00:00,  1.56it/s]
  0%|          | 0/3532 [00:00<?, ?it/s]  0%|          | 1/3532 [00:17<17:07:31, 17.46s/it]                                                   {'loss': 0.0, 'grad_norm': 0.2615605294704437, 'learning_rate': 1.4124293785310735e-08, 'rewards/degradation_reward_func': 0.0, 'rewards/improvement_reward_func': 0.625, 'rewards/xmlcount_reward_func': 0.03125, 'rewards/format_reward_func': 0.125, 'reward': 0.78125, 'reward_std': 0.7513009309768677, 'completion_length': 485.75, 'kl': 0.0, 'epoch': 0.0}
  0%|          | 1/3532 [00:17<17:07:31, 17.46s/it]  0%|          | 2/3532 [00:26<12:08:25, 12.38s/it]                                                   {'loss': -0.0, 'grad_norm': 0.4457588195800781, 'learning_rate': 2.824858757062147e-08, 'rewards/degradation_reward_func': 0.0, 'rewards/improvement_reward_func': 0.0, 'rewards/xmlcount_reward_func': 0.046875, 'rewards/format_reward_func': 0.375, 'reward': 0.421875, 'reward_std': 0.19887377880513668, 'completion_length': 181.375, 'kl': 0.0, 'epoch': 0.0}
  0%|          | 2/3532 [00:26<12:08:25, 12.38s/it]  0%|          | 3/3532 [00:37<11:49:45, 12.07s/it]                                                   {'loss': 0.0, 'grad_norm': 1.0648516416549683, 'learning_rate': 4.237288135593221e-08, 'rewards/degradation_reward_func': -1.25, 'rewards/improvement_reward_func': 0.0, 'rewards/xmlcount_reward_func': 0.0367499990388751, 'rewards/format_reward_func': 0.125, 'reward': -1.088250015862286, 'reward_std': 1.6429625684395432, 'completion_length': 304.25, 'kl': 0.00046957661834312603, 'epoch': 0.0}
  0%|          | 3/3532 [00:37<11:49:45, 12.07s/it]  0%|          | 4/3532 [00:53<13:08:21, 13.41s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5295496582984924, 'learning_rate': 5.649717514124294e-08, 'rewards/degradation_reward_func': 0.0, 'rewards/improvement_reward_func': 0.625, 'rewards/xmlcount_reward_func': 0.0, 'rewards/format_reward_func': 0.25, 'reward': 0.875, 'reward_std': 0.883883461356163, 'completion_length': 404.875, 'kl': 0.0004633994831237942, 'epoch': 0.0}
  0%|          | 4/3532 [00:53<13:08:21, 13.41s/it]  0%|          | 5/3532 [01:09<13:57:33, 14.25s/it]                                                   {'loss': 0.0, 'grad_norm': 0.18479669094085693, 'learning_rate': 7.062146892655368e-08, 'rewards/degradation_reward_func': -0.625, 'rewards/improvement_reward_func': 1.25, 'rewards/xmlcount_reward_func': 0.0, 'rewards/format_reward_func': 0.125, 'reward': 0.75, 'reward_std': 1.0606601238250732, 'completion_length': 435.625, 'kl': 0.00046324761933647096, 'epoch': 0.01}
  0%|          | 5/3532 [01:09<13:57:33, 14.25s/it]  0%|          | 6/3532 [01:26<14:59:19, 15.30s/it]                                                   {'loss': 0.0, 'grad_norm': 0.0011842732783406973, 'learning_rate': 8.474576271186442e-08, 'rewards/degradation_reward_func': 0.0, 'rewards/improvement_reward_func': 0.0, 'rewards/xmlcount_reward_func': 0.0, 'rewards/format_reward_func': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'completion_length': 547.625, 'kl': 0.00047541359526803717, 'epoch': 0.01}
  0%|          | 6/3532 [01:26<14:59:19, 15.30s/it]  0%|          | 7/3532 [01:50<17:38:27, 18.02s/it]                                                   {'loss': 0.0, 'grad_norm': 0.29085925221443176, 'learning_rate': 9.887005649717516e-08, 'rewards/degradation_reward_func': 0.0, 'rewards/improvement_reward_func': 0.625, 'rewards/xmlcount_reward_func': 0.0, 'rewards/format_reward_func': 0.125, 'reward': 0.75, 'reward_std': 1.0606601685285568, 'completion_length': 670.75, 'kl': 0.0003658987407106906, 'epoch': 0.01}
  0%|          | 7/3532 [01:50<17:38:27, 18.02s/it]  0%|          | 8/3532 [02:09<18:00:15, 18.39s/it]                                                   {'loss': 0.0, 'grad_norm': 0.27066826820373535, 'learning_rate': 1.1299435028248588e-07, 'rewards/degradation_reward_func': 0.0, 'rewards/improvement_reward_func': 0.625, 'rewards/xmlcount_reward_func': 0.03125, 'rewards/format_reward_func': 0.0, 'reward': 0.65625, 'reward_std': 0.9280776493251324, 'completion_length': 605.0, 'kl': 0.0004891206772299483, 'epoch': 0.01}
  0%|          | 8/3532 [02:09<18:00:15, 18.39s/it]  0%|          | 9/3532 [02:24<17:04:01, 17.44s/it]                                                   {'loss': 0.0, 'grad_norm': 0.40190473198890686, 'learning_rate': 1.2711864406779662e-07, 'rewards/degradation_reward_func': -1.25, 'rewards/improvement_reward_func': 0.0, 'rewards/xmlcount_reward_func': 0.0, 'rewards/format_reward_func': 0.5, 'reward': -0.75, 'reward_std': 0.3535533845424652, 'completion_length': 300.25, 'kl': 0.00038142655103001744, 'epoch': 0.01}
  0%|          | 9/3532 [02:24<17:04:01, 17.44s/it]  0%|          | 10/3532 [02:42<17:12:09, 17.58s/it]                                                    {'loss': 0.0, 'grad_norm': 0.3174706995487213, 'learning_rate': 1.4124293785310736e-07, 'rewards/degradation_reward_func': -0.625, 'rewards/improvement_reward_func': 0.0, 'rewards/xmlcount_reward_func': 0.0625, 'rewards/format_reward_func': 0.0, 'reward': -0.5625, 'reward_std': 0.9280776251107454, 'completion_length': 502.625, 'kl': 0.0005119436609675176, 'epoch': 0.01}
  0%|          | 10/3532 [02:42<17:12:09, 17.58s/it]  0%|          | 11/3532 [02:59<16:55:08, 17.30s/it]                                                    {'loss': 0.0, 'grad_norm': 0.34150463342666626, 'learning_rate': 1.553672316384181e-07, 'rewards/degradation_reward_func': 0.0, 'rewards/improvement_reward_func': 0.625, 'rewards/xmlcount_reward_func': 0.0, 'rewards/format_reward_func': 0.375, 'reward': 1.0, 'reward_std': 1.0606601536273956, 'completion_length': 494.75, 'kl': 0.00047792437544558197, 'epoch': 0.01}
  0%|          | 11/3532 [02:59<16:55:08, 17.30s/it]  0%|          | 12/3532 [03:13<16:07:48, 16.50s/it]                                                    {'loss': 0.0, 'grad_norm': 0.4391275644302368, 'learning_rate': 1.6949152542372883e-07, 'rewards/degradation_reward_func': 0.0, 'rewards/improvement_reward_func': 0.625, 'rewards/xmlcount_reward_func': 0.0625, 'rewards/format_reward_func': 0.25, 'reward': 0.9375, 'reward_std': 1.2374368570744991, 'completion_length': 401.375, 'kl': 0.00039069828926585615, 'epoch': 0.01}
  0%|          | 12/3532 [03:13<16:07:48, 16.50s/it]  0%|          | 13/3532 [03:32<16:38:13, 17.02s/it]                                                    {'loss': 0.0, 'grad_norm': 0.6388776898384094, 'learning_rate': 1.8361581920903958e-07, 'rewards/degradation_reward_func': 0.0, 'rewards/improvement_reward_func': 0.625, 'rewards/xmlcount_reward_func': 0.0, 'rewards/format_reward_func': 0.25, 'reward': 0.875, 'reward_std': 1.2374368607997894, 'completion_length': 539.0, 'kl': 0.000711249464075081, 'epoch': 0.01}
  0%|          | 13/3532 [03:32<16:38:13, 17.02s/it]  0%|          | 14/3532 [03:48<16:28:53, 16.87s/it]                                                    {'loss': 0.0, 'grad_norm': 0.3347874879837036, 'learning_rate': 1.9774011299435033e-07, 'rewards/degradation_reward_func': -1.25, 'rewards/improvement_reward_func': 0.0, 'rewards/xmlcount_reward_func': 0.046875, 'rewards/format_reward_func': 0.125, 'reward': -1.078125, 'reward_std': 2.0108348932117224, 'completion_length': 446.625, 'kl': 0.0004101466547581367, 'epoch': 0.02}
  0%|          | 14/3532 [03:48<16:28:53, 16.87s/it]  0%|          | 15/3532 [04:10<18:01:30, 18.45s/it]                                                    {'loss': 0.0, 'grad_norm': 0.2140381634235382, 'learning_rate': 2.1186440677966102e-07, 'rewards/degradation_reward_func': 0.0, 'rewards/improvement_reward_func': 0.0, 'rewards/xmlcount_reward_func': 0.0, 'rewards/format_reward_func': 0.125, 'reward': 0.125, 'reward_std': 0.1767766922712326, 'completion_length': 664.75, 'kl': 0.00038328563823597506, 'epoch': 0.02}
  0%|          | 15/3532 [04:10<18:01:30, 18.45s/it]  0%|          | 16/3532 [04:34<19:38:42, 20.11s/it]                                                    {'loss': 0.0, 'grad_norm': 0.25567761063575745, 'learning_rate': 2.2598870056497177e-07, 'rewards/degradation_reward_func': -0.625, 'rewards/improvement_reward_func': 0.625, 'rewards/xmlcount_reward_func': 0.0625, 'rewards/format_reward_func': 0.0, 'reward': 0.0625, 'reward_std': 1.8561552874743938, 'completion_length': 730.0, 'kl': 0.00039005597500363365, 'epoch': 0.02}
  0%|          | 16/3532 [04:34<19:38:42, 20.11s/it]  0%|          | 17/3532 [04:53<19:10:23, 19.64s/it]                                                    {'loss': 0.0, 'grad_norm': 0.3670196533203125, 'learning_rate': 2.401129943502825e-07, 'rewards/degradation_reward_func': 0.0, 'rewards/improvement_reward_func': 0.0, 'rewards/xmlcount_reward_func': 0.046875, 'rewards/format_reward_func': 0.125, 'reward': 0.171875, 'reward_std': 0.24306795187294483, 'completion_length': 550.375, 'kl': 0.0006058500803192146, 'epoch': 0.02}
  0%|          | 17/3532 [04:53<19:10:23, 19.64s/it][rank0]: Traceback (most recent call last):
[rank0]:   File "/workspace/rl_manipulation_human_baseline/train.py", line 224, in <module>
[rank0]:     trainer.train()
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2241, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 3692, in training_step
[rank0]:     inputs = self._prepare_inputs(inputs)
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 544, in _prepare_inputs
[rank0]:     outputs = self.llm.generate(all_prompts_text, sampling_params=self.sampling_params, use_tqdm=False)
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/vllm/utils.py", line 1057, in inner
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/vllm/entrypoints/llm.py", line 469, in generate
[rank0]:     outputs = self._run_engine(use_tqdm=use_tqdm)
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/vllm/entrypoints/llm.py", line 1397, in _run_engine
[rank0]:     step_outputs = self.llm_engine.step()
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 1391, in step
[rank0]:     outputs = self.model_executor.execute_model(
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 139, in execute_model
[rank0]:     output = self.collective_rpc("execute_model",
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
[rank0]:     answer = run_method(self.driver_worker, method, args, kwargs)
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/vllm/utils.py", line 2196, in run_method
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/vllm/worker/worker_base.py", line 420, in execute_model
[rank0]:     output = self.model_runner.execute_model(
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 1772, in execute_model
[rank0]:     logits = self.model.compute_logits(hidden_or_intermediate_states,
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 496, in compute_logits
[rank0]:     logits = self.logits_processor(self.lm_head, hidden_states,
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/vllm/model_executor/layers/logits_processor.py", line 74, in forward
[rank0]:     logits = self._get_logits(hidden_states, lm_head, embedding_bias)
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/vllm/model_executor/layers/logits_processor.py", line 111, in _get_logits
[rank0]:     logits = lm_head.quant_method.apply(lm_head,
[rank0]:   File "/workspace/rl_manipulation_human_baseline/.venv/lib/python3.10/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 43, in apply
[rank0]:     return F.linear(x, layer.weight, bias)
[rank0]: KeyboardInterrupt
  0%|          | 17/3532 [05:04<17:28:16, 17.89s/it]
K"
2025-03-20 14:17:53,945 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:17:57,830 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:17:58,249 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:01,758 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:02,494 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:11,335 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:11,871 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:17,306 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:17,851 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:20,412 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:21,083 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:24,830 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:25,351 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:31,485 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:32,006 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:35,971 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:36,426 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:39,127 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:39,679 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:44,069 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-03-20 14:18:44,496 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
